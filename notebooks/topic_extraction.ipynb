{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "745f0c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the reduced dataset\n",
    "df_train = pd.read_csv(\"train_small.csv\")\n",
    "df_test = pd.read_csv(\"test_small.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fd19692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentiment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label sentiment_text\n",
       "0      2       positive\n",
       "1      2       positive\n",
       "2      1       negative\n",
       "3      2       positive\n",
       "4      2       positive"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = {1: \"negative\", 2: \"positive\"}\n",
    "\n",
    "df_train[\"sentiment_text\"] = df_train[\"label\"].map(label_map)\n",
    "df_test[\"sentiment_text\"]  = df_test[\"label\"].map(label_map)\n",
    "\n",
    "df_train[[\"label\", \"sentiment_text\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2701a3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_small[\"clean_review\"] = df_train_small[\"review\"].apply(clean_text)\n",
    "df_test_small[\"clean_review\"]  = df_test_small[\"review\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1acf7234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive words:\n",
      " [('the', 181201), ('and', 111201), ('i', 102520), ('a', 95802), ('to', 89381), ('it', 82073), ('of', 75724), ('is', 69126), ('this', 67892), ('in', 46193), ('for', 41277), ('that', 36607), ('you', 34923), ('s', 29921), ('with', 28471), ('was', 26420), ('my', 25667), ('book', 25324), ('on', 25245), ('but', 24084)]\n",
      "\n",
      "Top negative words:\n",
      " [('the', 203650), ('i', 123779), ('to', 98461), ('and', 98401), ('a', 93496), ('it', 92441), ('of', 74271), ('this', 74165), ('is', 64211), ('in', 44270), ('that', 42434), ('for', 39975), ('was', 39120), ('not', 38125), ('you', 32180), ('t', 31358), ('but', 30934), ('on', 29281), ('with', 27464), ('s', 26823)]\n"
     ]
    }
   ],
   "source": [
    "pos_words = \" \".join(df_train[df_train[\"sentiment_text\"]==\"positive\"][\"clean_review\"]).split()\n",
    "neg_words = \" \".join(df_train[df_train[\"sentiment_text\"]==\"negative\"][\"clean_review\"]).split()\n",
    "\n",
    "pos_counts = Counter(pos_words).most_common(20)\n",
    "neg_counts = Counter(neg_words).most_common(20)\n",
    "\n",
    "print(\"Top positive words:\\n\", pos_counts)\n",
    "print(\"\\nTop negative words:\\n\", neg_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "467fecd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and labels (y)\n",
    "X = df_train[\"clean_review\"]     # input text\n",
    "y = df_train[\"label\"]            # sentiment label (1=neg, 2=pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7ff56467",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_small.to_csv(\"train_small.csv\", index=False)\n",
    "df_test_small.to_csv(\"test_small.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "26005ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rake-nltk\n",
      "  Downloading rake_nltk-1.0.6-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.6.2 in /Users/varsharavi/anaconda3/lib/python3.11/site-packages (from rake-nltk) (3.8.1)\n",
      "Requirement already satisfied: click in /Users/varsharavi/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/varsharavi/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/varsharavi/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in /Users/varsharavi/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (4.65.0)\n",
      "Downloading rake_nltk-1.0.6-py3-none-any.whl (9.1 kB)\n",
      "Installing collected packages: rake-nltk\n",
      "Successfully installed rake-nltk-1.0.6\n",
      "Topic #0:\n",
      "['time', 'author', 'reading', 'just', 'good', 'like', 'books', 'story', 'read', 'book']\n",
      "\n",
      "Topic #1:\n",
      "['love', 'really', 'little', 'good', 'great', 'water', 'product', 'use', 'just', 'like']\n",
      "\n",
      "Topic #2:\n",
      "['film', 'songs', 'great', 'music', 'just', 'good', 'album', 'cd', 'like', 'movie']\n",
      "\n",
      "Topic #3:\n",
      "['received', 'great', 'got', 'time', 'year', 'product', 'bought', 'dvd', 'old', 'amazon']\n",
      "\n",
      "Topic #4:\n",
      "['buy', 'like', 'time', 'bought', 'great', 'work', 'good', 'product', 'just', 'use']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pos_reviews = df_train_small[df_train_small[\"label\"] == 2][\"clean_review\"]\n",
    "neg_reviews = df_train_small[df_train_small[\"label\"] == 1][\"clean_review\"]\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def get_top_ngrams(corpus, n=None, ngram_range=(2,2)):\n",
    "    vec = CountVectorizer(ngram_range=ngram_range).fit(corpus)\n",
    "    bag = vec.transform(corpus)\n",
    "    sum_words = bag.sum(axis=0)\n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "\n",
    "top_pos_bigrams = get_top_ngrams(pos_reviews, n=20, ngram_range=(2,2))\n",
    "top_neg_bigrams = get_top_ngrams(neg_reviews, n=20, ngram_range=(2,2))\n",
    "\n",
    "!pip install rake-nltk\n",
    "from rake_nltk import Rake\n",
    "\n",
    "r = Rake()\n",
    "\n",
    "def extract_key_phrases(text_series, top_n=20):\n",
    "    r.extract_keywords_from_sentences(text_series)\n",
    "    return r.get_ranked_phrases()[:top_n]\n",
    "\n",
    "pos_phrases = extract_key_phrases(pos_reviews[:2000])\n",
    "neg_phrases = extract_key_phrases(neg_reviews[:2000])\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "vectorizer = CountVectorizer(max_df=0.9, min_df=10, stop_words='english')\n",
    "X = vectorizer.fit_transform(df_train_small[\"clean_review\"])\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "lda.fit(X)\n",
    "\n",
    "words = vectorizer.get_feature_names_out()\n",
    "\n",
    "for idx, topic in enumerate(lda.components_):\n",
    "    print(f\"Topic #{idx}:\")\n",
    "    print([words[i] for i in topic.argsort()[-10:]])\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
